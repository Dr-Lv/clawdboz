#!/usr/bin/env python3
"""
Local Memory Management - æœ¬åœ°è®°å¿†ç®¡ç†
æ”¯æŒä¿å­˜ã€æ£€ç´¢ã€ç®¡ç†è®°å¿†ï¼Œæä¾›å…³é”®è¯æœç´¢å’Œè¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…
"""

import os
import json
import sqlite3
import hashlib
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Any
from dataclasses import dataclass, asdict


@dataclass
class Memory:
    """è®°å¿†æ¡ç›®"""
    id: str
    content: str
    category: str
    tags: List[str]
    importance: int  # 1-5ï¼Œ5ä¸ºæœ€é‡è¦
    created_at: str
    updated_at: str
    access_count: int = 0
    last_accessed: Optional[str] = None


class MemoryManager:
    """æœ¬åœ°è®°å¿†ç®¡ç†å™¨"""
    
    def __init__(self, storage_dir: Optional[str] = None):
        """åˆå§‹åŒ–è®°å¿†ç®¡ç†å™¨
        
        Args:
            storage_dir: å­˜å‚¨ç›®å½•ï¼Œé»˜è®¤ ~/.local/share/local-memory/
        """
        if storage_dir is None:
            storage_dir = os.path.expanduser("~/.local/share/local-memory")
        
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        self.db_path = self.storage_dir / "memories.db"
        self.embeddings_dir = self.storage_dir / "embeddings"
        self.embeddings_dir.mkdir(exist_ok=True)
        
        self._init_db()
    
    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS memories (
                    id TEXT PRIMARY KEY,
                    content TEXT NOT NULL,
                    category TEXT DEFAULT 'general',
                    tags TEXT DEFAULT '[]',
                    importance INTEGER DEFAULT 3,
                    created_at TEXT NOT NULL,
                    updated_at TEXT NOT NULL,
                    access_count INTEGER DEFAULT 0,
                    last_accessed TEXT
                )
            """)
            
            # åˆ›å»ºç´¢å¼•
            conn.execute("CREATE INDEX IF NOT EXISTS idx_category ON memories(category)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_created ON memories(created_at)")
            conn.commit()
    
    def _generate_id(self, content: str) -> str:
        """ç”Ÿæˆè®°å¿†ID"""
        timestamp = datetime.now().isoformat()
        return hashlib.md5(f"{content}{timestamp}".encode()).hexdigest()[:12]
    
    def save(self, content: str, category: str = "general", 
             tags: Optional[List[str]] = None, importance: int = 3) -> str:
        """ä¿å­˜è®°å¿†
        
        Args:
            content: è®°å¿†å†…å®¹
            category: åˆ†ç±»ï¼Œé»˜è®¤ general
            tags: æ ‡ç­¾åˆ—è¡¨
            importance: é‡è¦ç¨‹åº¦ 1-5
            
        Returns:
            memory_id: è®°å¿†ID
        """
        if tags is None:
            tags = []
        
        memory_id = self._generate_id(content)
        now = datetime.now().isoformat()
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT OR REPLACE INTO memories 
                (id, content, category, tags, importance, created_at, updated_at, access_count)
                VALUES (?, ?, ?, ?, ?, ?, ?, 0)
            """, (
                memory_id, content, category, 
                json.dumps(tags, ensure_ascii=False),
                importance, now, now
            ))
            conn.commit()
        
        # ä¿å­˜è¯­ä¹‰å‘é‡ï¼ˆç®€åŒ–å®ç°ï¼šåŸºäºå…³é”®è¯çš„å“ˆå¸Œï¼‰
        self._save_embedding(memory_id, content)
        
        return memory_id
    
    def _save_embedding(self, memory_id: str, content: str):
        """ä¿å­˜è¯­ä¹‰å‘é‡ï¼ˆç®€åŒ–ç‰ˆï¼šå…³é”®è¯é¢‘ç‡ï¼‰"""
        # æå–å…³é”®è¯ï¼ˆç®€åŒ–å¤„ç†ï¼‰
        words = re.findall(r'\w+', content.lower())
        word_freq = {}
        for word in words:
            if len(word) > 1:
                word_freq[word] = word_freq.get(word, 0) + 1
        
        embedding_path = self.embeddings_dir / f"{memory_id}.json"
        with open(embedding_path, 'w', encoding='utf-8') as f:
            json.dump(word_freq, f, ensure_ascii=False)
    
    def _compute_similarity(self, query_words: Dict[str, int], memory_id: str) -> float:
        """è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦"""
        embedding_path = self.embeddings_dir / f"{memory_id}.json"
        if not embedding_path.exists():
            return 0.0
        
        with open(embedding_path, 'r', encoding='utf-8') as f:
            memory_words = json.load(f)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰
        common_words = set(query_words.keys()) & set(memory_words.keys())
        if not common_words:
            return 0.0
        
        dot_product = sum(query_words[w] * memory_words[w] for w in common_words)
        query_norm = sum(v**2 for v in query_words.values()) ** 0.5
        memory_norm = sum(v**2 for v in memory_words.values()) ** 0.5
        
        if query_norm == 0 or memory_norm == 0:
            return 0.0
        
        return dot_product / (query_norm * memory_norm)
    
    def search(self, keyword: str, category: Optional[str] = None) -> List[Dict]:
        """å…³é”®è¯æœç´¢
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            category: å¯é€‰çš„åˆ†ç±»è¿‡æ»¤
            
        Returns:
            åŒ¹é…çš„è®°å¿†åˆ—è¡¨
        """
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            
            if category:
                cursor = conn.execute(
                    "SELECT * FROM memories WHERE category = ? AND content LIKE ? ORDER BY created_at DESC",
                    (category, f"%{keyword}%")
                )
            else:
                cursor = conn.execute(
                    "SELECT * FROM memories WHERE content LIKE ? ORDER BY created_at DESC",
                    (f"%{keyword}%",)
                )
            
            rows = cursor.fetchall()
        
        results = []
        for row in rows:
            memory = dict(row)
            memory['tags'] = json.loads(memory['tags'])
            results.append(memory)
            
            # æ›´æ–°è®¿é—®è®¡æ•°
            self._update_access_count(memory['id'])
        
        return results
    
    def search_similar(self, query: str, top_k: int = 5) -> List[Dict]:
        """è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢
        
        Args:
            query: æŸ¥è¯¢å†…å®¹
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æœ€ç›¸å…³çš„è®°å¿†åˆ—è¡¨
        """
        # æ„å»ºæŸ¥è¯¢å‘é‡
        words = re.findall(r'\w+', query.lower())
        query_words = {}
        for word in words:
            if len(word) > 1:
                query_words[word] = query_words.get(word, 0) + 1
        
        # è·å–æ‰€æœ‰è®°å¿†
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("SELECT * FROM memories")
            all_memories = [dict(row) for row in cursor.fetchall()]
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = []
        for memory in all_memories:
            sim = self._compute_similarity(query_words, memory['id'])
            similarities.append((memory, sim))
        
        # æ’åºå¹¶è¿”å› top_k
        similarities.sort(key=lambda x: x[1], reverse=True)
        results = []
        for memory, sim in similarities[:top_k]:
            if sim > 0:  # åªè¿”å›æœ‰ç›¸ä¼¼åº¦çš„
                memory['tags'] = json.loads(memory['tags'])
                memory['similarity'] = round(sim, 4)
                results.append(memory)
                self._update_access_count(memory['id'])
        
        return results
    
    def _update_access_count(self, memory_id: str):
        """æ›´æ–°è®¿é—®è®¡æ•°"""
        now = datetime.now().isoformat()
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(
                "UPDATE memories SET access_count = access_count + 1, last_accessed = ? WHERE id = ?",
                (now, memory_id)
            )
            conn.commit()
    
    def get(self, memory_id: str) -> Optional[Dict]:
        """è·å–å•ä¸ªè®°å¿†
        
        Args:
            memory_id: è®°å¿†ID
            
        Returns:
            è®°å¿†å†…å®¹ï¼Œä¸å­˜åœ¨è¿”å› None
        """
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("SELECT * FROM memories WHERE id = ?", (memory_id,))
            row = cursor.fetchone()
        
        if row:
            memory = dict(row)
            memory['tags'] = json.loads(memory['tags'])
            self._update_access_count(memory_id)
            return memory
        return None
    
    def delete(self, memory_id: str) -> bool:
        """åˆ é™¤è®°å¿†
        
        Args:
            memory_id: è®°å¿†ID
            
        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("DELETE FROM memories WHERE id = ?", (memory_id,))
            conn.commit()
        
        # åˆ é™¤åµŒå…¥å‘é‡
        embedding_path = self.embeddings_dir / f"{memory_id}.json"
        if embedding_path.exists():
            embedding_path.unlink()
        
        return cursor.rowcount > 0
    
    def update(self, memory_id: str, **kwargs) -> bool:
        """æ›´æ–°è®°å¿†
        
        Args:
            memory_id: è®°å¿†ID
            **kwargs: è¦æ›´æ–°çš„å­—æ®µ
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        allowed_fields = {'content', 'category', 'tags', 'importance'}
        updates = {k: v for k, v in kwargs.items() if k in allowed_fields}
        
        if not updates:
            return False
        
        if 'tags' in updates:
            updates['tags'] = json.dumps(updates['tags'], ensure_ascii=False)
        
        updates['updated_at'] = datetime.now().isoformat()
        
        set_clause = ', '.join(f"{k} = ?" for k in updates.keys())
        values = list(updates.values()) + [memory_id]
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                f"UPDATE memories SET {set_clause} WHERE id = ?",
                values
            )
            conn.commit()
        
        # å¦‚æœå†…å®¹æ›´æ–°ï¼Œé‡æ–°è®¡ç®—åµŒå…¥
        if 'content' in updates:
            self._save_embedding(memory_id, kwargs['content'])
        
        return cursor.rowcount > 0
    
    def list_all(self, category: Optional[str] = None, limit: int = 100) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰è®°å¿†
        
        Args:
            category: å¯é€‰çš„åˆ†ç±»è¿‡æ»¤
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            è®°å¿†åˆ—è¡¨
        """
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            
            if category:
                cursor = conn.execute(
                    "SELECT * FROM memories WHERE category = ? ORDER BY created_at DESC LIMIT ?",
                    (category, limit)
                )
            else:
                cursor = conn.execute(
                    "SELECT * FROM memories ORDER BY created_at DESC LIMIT ?",
                    (limit,)
                )
            
            rows = cursor.fetchall()
        
        results = []
        for row in rows:
            memory = dict(row)
            memory['tags'] = json.loads(memory['tags'])
            results.append(memory)
        
        return results
    
    def cleanup(self, days: int = 30) -> int:
        """æ¸…ç†æ—§è®°å¿†
        
        Args:
            days: åˆ é™¤å¤šå°‘å¤©å‰çš„è®°å¿†
            
        Returns:
            åˆ é™¤çš„è®°å¿†æ•°é‡
        """
        cutoff_date = (datetime.now() - timedelta(days=days)).isoformat()
        
        with sqlite3.connect(self.db_path) as conn:
            # è·å–è¦åˆ é™¤çš„ID
            cursor = conn.execute(
                "SELECT id FROM memories WHERE created_at < ?",
                (cutoff_date,)
            )
            ids_to_delete = [row[0] for row in cursor.fetchall()]
            
            # åˆ é™¤è®°å½•
            cursor = conn.execute("DELETE FROM memories WHERE created_at < ?", (cutoff_date,))
            deleted_count = cursor.rowcount
            conn.commit()
        
        # åˆ é™¤å¯¹åº”çš„åµŒå…¥æ–‡ä»¶
        for memory_id in ids_to_delete:
            embedding_path = self.embeddings_dir / f"{memory_id}.json"
            if embedding_path.exists():
                embedding_path.unlink()
        
        return deleted_count
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–è®°å¿†åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        with sqlite3.connect(self.db_path) as conn:
            # æ€»æ•°é‡
            cursor = conn.execute("SELECT COUNT(*) FROM memories")
            total = cursor.fetchone()[0]
            
            # åˆ†ç±»ç»Ÿè®¡
            cursor = conn.execute(
                "SELECT category, COUNT(*) FROM memories GROUP BY category"
            )
            by_category = {row[0]: row[1] for row in cursor.fetchall()}
            
            # æœ€è¿‘æ·»åŠ 
            cursor = conn.execute(
                "SELECT COUNT(*) FROM memories WHERE created_at > ?",
                ((datetime.now() - timedelta(days=7)).isoformat(),)
            )
            recent = cursor.fetchone()[0]
            
            # æœ€å¸¸è®¿é—®
            cursor = conn.execute(
                "SELECT id, content, access_count FROM memories ORDER BY access_count DESC LIMIT 5"
            )
            most_accessed = [
                {'id': row[0], 'content': row[1][:50] + '...', 'access_count': row[2]}
                for row in cursor.fetchall()
            ]
        
        return {
            'total_memories': total,
            'by_category': by_category,
            'recent_7_days': recent,
            'most_accessed': most_accessed,
            'storage_dir': str(self.storage_dir)
        }
    
    def export(self, output_path: str):
        """å¯¼å‡ºæ‰€æœ‰è®°å¿†åˆ° JSON æ–‡ä»¶
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        memories = self.list_all(limit=10000)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(memories, f, ensure_ascii=False, indent=2)
    
    def import_from(self, input_path: str):
        """ä» JSON æ–‡ä»¶å¯¼å…¥è®°å¿†
        
        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
        """
        with open(input_path, 'r', encoding='utf-8') as f:
            memories = json.load(f)
        
        for memory in memories:
            self.save(
                content=memory['content'],
                category=memory.get('category', 'general'),
                tags=memory.get('tags', []),
                importance=memory.get('importance', 3)
            )


# CLI æ¥å£
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Local Memory Management")
    subparsers = parser.add_subparsers(dest='command', help='Commands')
    
    # save
    save_parser = subparsers.add_parser('save', help='Save a memory')
    save_parser.add_argument('content', help='Memory content')
    save_parser.add_argument('--category', '-c', default='general', help='Category')
    save_parser.add_argument('--tags', '-t', default='', help='Tags (comma-separated)')
    save_parser.add_argument('--importance', '-i', type=int, default=3, help='Importance (1-5)')
    
    # search
    search_parser = subparsers.add_parser('search', help='Search memories by keyword')
    search_parser.add_argument('keyword', help='Search keyword')
    search_parser.add_argument('--category', '-c', help='Filter by category')
    
    # similar
    similar_parser = subparsers.add_parser('similar', help='Semantic search')
    similar_parser.add_argument('query', help='Query text')
    similar_parser.add_argument('--top-k', '-k', type=int, default=5, help='Number of results')
    
    # list
    list_parser = subparsers.add_parser('list', help='List all memories')
    list_parser.add_argument('--category', '-c', help='Filter by category')
    list_parser.add_argument('--limit', '-l', type=int, default=20, help='Limit')
    
    # delete
    delete_parser = subparsers.add_parser('delete', help='Delete a memory')
    delete_parser.add_argument('memory_id', help='Memory ID')
    
    # cleanup
    cleanup_parser = subparsers.add_parser('cleanup', help='Clean up old memories')
    cleanup_parser.add_argument('--days', '-d', type=int, default=30, help='Days to keep')
    
    # stats
    stats_parser = subparsers.add_parser('stats', help='Show statistics')
    
    # export
    export_parser = subparsers.add_parser('export', help='Export memories')
    export_parser.add_argument('--output', '-o', default='memories.json', help='Output file')
    
    # import
    import_parser = subparsers.add_parser('import', help='Import memories')
    import_parser.add_argument('--input', '-i', required=True, help='Input file')
    
    args = parser.parse_args()
    
    memory = MemoryManager()
    
    if args.command == 'save':
        tags = [t.strip() for t in args.tags.split(',') if t.strip()]
        mid = memory.save(args.content, args.category, tags, args.importance)
        print(f"âœ… Saved with ID: {mid}")
    
    elif args.command == 'search':
        results = memory.search(args.keyword, args.category)
        print(f"ğŸ” Found {len(results)} results:")
        for r in results:
            print(f"  [{r['id'][:8]}] {r['content'][:60]}... ({r['category']})")
    
    elif args.command == 'similar':
        results = memory.search_similar(args.query, args.top_k)
        print(f"ğŸ” Found {len(results)} similar memories:")
        for r in results:
            sim_pct = r.get('similarity', 0) * 100
            print(f"  [{r['id'][:8]}] ({sim_pct:.1f}%) {r['content'][:50]}...")
    
    elif args.command == 'list':
        results = memory.list_all(args.category, args.limit)
        print(f"ğŸ“‹ {len(results)} memories:")
        for r in results:
            print(f"  [{r['id'][:8]}] [{r['category']}] {r['content'][:50]}...")
    
    elif args.command == 'delete':
        if memory.delete(args.memory_id):
            print(f"âœ… Deleted {args.memory_id}")
        else:
            print(f"âŒ Not found: {args.memory_id}")
    
    elif args.command == 'cleanup':
        count = memory.cleanup(args.days)
        print(f"ğŸ§¹ Cleaned up {count} old memories")
    
    elif args.command == 'stats':
        stats = memory.get_stats()
        print(f"ğŸ“Š Memory Statistics:")
        print(f"  Total: {stats['total_memories']}")
        print(f"  Recent (7 days): {stats['recent_7_days']}")
        print(f"  By category: {stats['by_category']}")
        print(f"  Storage: {stats['storage_dir']}")
    
    elif args.command == 'export':
        memory.export(args.output)
        print(f"âœ… Exported to {args.output}")
    
    elif args.command == 'import':
        memory.import_from(args.input)
        print(f"âœ… Imported from {args.input}")
    
    else:
        parser.print_help()
